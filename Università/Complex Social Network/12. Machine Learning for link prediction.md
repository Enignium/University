### **Limiti delle Classical Heuristics**

Le euristiche classiche per il link prediction si basano esclusivamente sulla **struttura del grafo**, osservando come i nodi sono collegati. Questo le rende semplici ma rigide:

- Non possono usare **attributi dei nodi** (es. età, ruolo) o **proprietà degli archi** (pesi, tipo di interazione, tempo).

- Il modello è **fisso** e non apprende dai dati, quindi non cattura pattern complessi né migliora con più informazioni.

- Le prestazioni dipendono fortemente dalla **topologia**: funzionano bene in grafi con triadi, alto clustering e nodi hub, ma crollano in reti sparse o non scale-free.

> [!warning]  
> Il problema principale: **le euristiche funzionano solo se la rete “assomiglia” alla struttura che l’euristica si aspetta**. Se la rete reale è diversa, l’accuratezza si abbassa drasticamente.
### **Approcci di Machine Learning**

Gli approcci basati sul machine learning formulano il link prediction come un problema di **classificazione supervisionata**: ogni possibile coppia di nodi (x, y) è un esempio da etichettare come “link” o “no link”.  
Ogni coppia viene convertita in un **feature vector**, cioè un insieme di caratteristiche che descrivono la relazione tra i due nodi.
Il modello apprende dai link esistenti quali combinazioni di segnali sono realmente predittive e generalizza a coppie nuove.

> [!note]  
> Le euristiche classiche non vengono eliminate: possono essere integrate come **feature topologiche**, diventando uno dei segnali disponibili al modello ML.
### **Common Features**

Le feature utilizzate nei modelli di ML per il link prediction derivano da diverse fonti della rete:
### **1. Topological Heuristics (come feature)**

- Common Neighbors
- Adamic–Adar
- Jaccard
- Preferential Attachment
- Katz index  
Queste misure sintetizzano la **prossimità strutturale** tra due nodi.

### **2. Node Attributes**

- Similarità tra profili
- Appartenenza a gruppi
- Etichette categoriali  
Aiutano a stabilire se due nodi hanno caratteristiche compatibili.
### **3. Edge Attributes**

- Peso dell’interazione
- Timestamp
- Tipo di relazione  
Rappresentano l’intensità, il contesto e la natura del legame.
### **4. Node Embeddings**

- Vettori generati da Node2Vec, DeepWalk, LINE, ecc.  
Catturano pattern strutturali complessi e informazioni globali in uno spazio continuo.

> [!tip]  
> **La forza degli approcci ML è la combinazione di più fonti di informazione**, impossibile per le heuristics pure.

### **Feature Representation**

AGGIUNGI GRAFICO

Per ogni coppia non collegata (x, y), si crea un vettore che rappresenta **quanto i due nodi risultano compatibili** secondo segnali topologici, attributi e embedding.  
Questo vettore diventa l’input del modello supervisionato, che restituisce la probabilità di formazione del link.

> [!info]  
> In pratica:  
> **nodi → feature vector → classificatore → probabilità link.**
### **Confusion Matrix (esempio semplice)**

|TP|FP|
|---|---|
|FN|TN|

- **TP**: è un “gatto” e il modello lo riconosce.
- **FP**: non è un gatto, ma il modello dice che lo è.
- **FN**: è un gatto ma il modello non lo riconosce.
- **TN**: non è un gatto e il modello lo identifica correttamente.

> [!tip]  
> In link prediction, “gatto” = “link esiste”.  
> La matrice serve per valutare quanti collegamenti il modello ha previsto correttamente o meno.
### **Vantaggi del Machine Learning**

> [!success] **Ricorda**
> 
> - Impara **dalla rete reale**, non da formule fisse.
>     
> - Incorpora facilmente **attributi, tempo, pesi, embedding**.
>     
> - Modello flessibile che si **adatta** alla struttura dei dati.
>     
> - Prestazioni spesso **superiori** alle euristiche, soprattutto in reti complesse.
>     
> - Rende il link prediction un problema generale applicabile a qualunque rete.
>     

### **Confronto tra predizione ML e CN**

AGGIUNGI GRAFICO

Il grafico mostra la differenza tra una semplice euristica di link prediction (es. Common Neighbors) e un modello di machine learning applicato sullo stesso grafo.

- Le linee blu tratteggiate mostrano i link predetti da CN: concentrati nelle zone dense e ricche di triadi.
- Le linee rosse rappresentano le predizioni del modello ML: distribuite anche in zone meno ovvie della rete.

> [!important]  Importante
> CN vede solo la **struttura locale** e predice link dove ci sono molti vicini comuni;  
> il ML vede **struttura + attributi + embedding** e può predire connessioni più complesse.

Indichiamo il feature vector come:

$$
\mathbf{x}_{(x,y)} = [S_{CN}(x,y), S_{AA}(x,y), S_{J}(x,y), \text{node attributes}, \text{edge attributes}, \text{embeddings}]$$

> [!info]  
> Ogni coppia di nodi diventa un punto nello spazio delle feature. È questo vettore che il modello usa per capire se i due nodi dovrebbero essere collegati.
## **Ground truth label**

Per addestrare il classificatore serve l’etichetta vera (“c’è il link oppure no?”) per ogni coppia $(x, y)$.

La label è:
$$Y_{(x,y)} =
\begin{cases}
1 & \text{se l'arco esiste, o se è stato nascosto apposta per il test} \\
0 & \text{altrimenti}
\end{cases}$$

> [!tip]  
> Durante il training, 1 = link presente.  
> Durante il testing, 1 = link **nascosto apposta** per vedere se il modello lo ritrova.
## **Train/Test splitting**

Per valutare il modello è necessario dividere la rete in due parti:

- una parte usata per **addestrare** il classificatore (training set)
- una parte **nascosta** per testare la capacità predittiva (test set)

> [!warning]  
> Senza nascondere alcuni link reali, il modello potrebbe semplicemente memorizzare la rete invece di imparare pattern generali.
## **ML Workflow**

### **Training set**

- **Positivi**: tutti gli archi reali **non nascosti**, cioè quelli osservabili nella rete.
- **Negativi**: un numero uguale (o maggiore) di coppie **non collegate**, scelte a caso tra i non-edge della rete.
### **Test set**

- **Positivi**: gli archi **nascosti apposta** (hidden edges), cioè quelli che il modello deve riuscire a ritrovare.
- **Negativi**: coppie non collegate scelte a caso, per confrontare le predizioni.

> [!important]  Importante
> Il bilanciamento tra link e non-link è cruciale: la rete è molto sparsa, quindi i negativi sono tantissimi. Serve un campionamento controllato per evitare che il modello impari solo a dire “0”.
